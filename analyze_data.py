#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CMeIE æ•°æ®é›†åˆ†æè„šæœ¬
ç”¨äºç»Ÿè®¡æ•°æ®é›†ä¸­çš„å…³ç³»ç±»å‹ã€å®ä½“ç±»å‹ç­‰ä¿¡æ¯
"""

import json
from collections import Counter
from pathlib import Path


def analyze_cmeie_dataset(file_path):
    """åˆ†æ CMeIE æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
    
    print(f"ğŸ“Š å¼€å§‹åˆ†ææ•°æ®é›†: {file_path}\n")
    
    # ç»Ÿè®¡å˜é‡
    total_samples = 0
    total_spo = 0
    predicates = []  # å…³ç³»ç±»å‹
    subject_types = []  # ä¸»ä½“ç±»å‹
    object_types = []  # å®¢ä½“ç±»å‹
    text_lengths = []  # æ–‡æœ¬é•¿åº¦
    
    # è¯»å–æ•°æ®
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            total_samples += 1
            data = json.loads(line)
            text = data['text']
            text_lengths.append(len(text))
            
            spo_list = data['spo_list']
            total_spo += len(spo_list)
            
            for spo in spo_list:
                predicates.append(spo['predicate'])
                subject_types.append(spo['subject_type'])
                object_types.append(spo['object_type']['@value'])
    
    # æ‰“å°åŸºæœ¬ç»Ÿè®¡
    print("=" * 60)
    print("ğŸ“ˆ åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯")
    print("=" * 60)
    print(f"æ ·æœ¬æ€»æ•°: {total_samples:,}")
    print(f"ä¸‰å…ƒç»„æ€»æ•°: {total_spo:,}")
    print(f"å¹³å‡æ¯ä¸ªæ ·æœ¬çš„ä¸‰å…ƒç»„æ•°: {total_spo / total_samples:.2f}")
    print(f"å¹³å‡æ–‡æœ¬é•¿åº¦: {sum(text_lengths) / len(text_lengths):.1f} å­—")
    print(f"æœ€çŸ­æ–‡æœ¬: {min(text_lengths)} å­—")
    print(f"æœ€é•¿æ–‡æœ¬: {max(text_lengths)} å­—")
    
    # å…³ç³»ç±»å‹ç»Ÿè®¡
    print("\n" + "=" * 60)
    print("ğŸ”— å…³ç³»ç±»å‹ç»Ÿè®¡ (Top 15)")
    print("=" * 60)
    predicate_counter = Counter(predicates)
    for i, (pred, count) in enumerate(predicate_counter.most_common(15), 1):
        percentage = count / len(predicates) * 100
        print(f"{i:2d}. {pred:20s}: {count:5,} ({percentage:5.2f}%)")
    
    print(f"\nå…³ç³»ç±»å‹æ€»æ•°: {len(predicate_counter)}")
    
    # å®ä½“ç±»å‹ç»Ÿè®¡
    print("\n" + "=" * 60)
    print("ğŸ·ï¸  å®ä½“ç±»å‹ç»Ÿè®¡")
    print("=" * 60)
    all_types = subject_types + object_types
    type_counter = Counter(all_types)
    for i, (etype, count) in enumerate(type_counter.most_common(), 1):
        percentage = count / len(all_types) * 100
        print(f"{i:2d}. {etype:20s}: {count:5,} ({percentage:5.2f}%)")
    
    # æ–‡æœ¬é•¿åº¦åˆ†å¸ƒ
    print("\n" + "=" * 60)
    print("ğŸ“ æ–‡æœ¬é•¿åº¦åˆ†å¸ƒ")
    print("=" * 60)
    length_ranges = [
        ("0-50å­—", 0, 50),
        ("51-100å­—", 51, 100),
        ("101-200å­—", 101, 200),
        ("201-500å­—", 201, 500),
        ("500å­—ä»¥ä¸Š", 501, float('inf'))
    ]
    
    for label, min_len, max_len in length_ranges:
        count = sum(1 for l in text_lengths if min_len <= l <= max_len)
        percentage = count / len(text_lengths) * 100
        print(f"{label:12s}: {count:5,} ({percentage:5.2f}%)")


def sample_data_examples(file_path, n=3):
    """å±•ç¤ºæ•°æ®æ ·ä¾‹"""
    
    print("\n" + "=" * 60)
    print(f"ğŸ“ æ•°æ®æ ·ä¾‹ (éšæœºæŠ½å– {n} æ¡)")
    print("=" * 60)
    
    import random
    
    # è¯»å–æ‰€æœ‰æ•°æ®
    samples = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            samples.append(json.loads(line))
    
    # éšæœºæŠ½å–
    selected = random.sample(samples, min(n, len(samples)))
    
    for i, sample in enumerate(selected, 1):
        print(f"\nã€æ ·ä¾‹ {i}ã€‘")
        print(f"æ–‡æœ¬: {sample['text'][:100]}{'...' if len(sample['text']) > 100 else ''}")
        print(f"ä¸‰å…ƒç»„æ•°é‡: {len(sample['spo_list'])}")
        
        for j, spo in enumerate(sample['spo_list'][:3], 1):  # åªæ˜¾ç¤ºå‰3ä¸ª
            print(f"\n  ä¸‰å…ƒç»„ {j}:")
            print(f"    Subject: {spo['subject']} ({spo['subject_type']})")
            print(f"    Predicate: {spo['predicate']}")
            print(f"    Object: {spo['object']['@value']} ({spo['object_type']['@value']})")
        
        if len(sample['spo_list']) > 3:
            print(f"\n  ... è¿˜æœ‰ {len(sample['spo_list']) - 3} ä¸ªä¸‰å…ƒç»„")


if __name__ == "__main__":
    # æ•°æ®æ–‡ä»¶è·¯å¾„
    data_file = Path(__file__).parent / "data" / "annotated_data" / "CMeIE-V2.jsonl"
    
    if not data_file.exists():
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        print("è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶åœ¨æ­£ç¡®çš„ä½ç½®")
    else:
        # æ‰§è¡Œåˆ†æ
        analyze_cmeie_dataset(data_file)
        
        # æ˜¾ç¤ºæ ·ä¾‹
        sample_data_examples(data_file, n=3)
        
        print("\n" + "=" * 60)
        print("âœ… åˆ†æå®Œæˆï¼")
        print("=" * 60)
